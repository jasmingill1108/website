---
title: 'Project 2: Modeling, Testing, and Predicting'
author: "SDS348 Fall 2019"
date: "2019-12-10"
output:
  pdf_document:
    toc: yes
  html_document:
    toc: yes
    toc_float:
      collapsed: no
      smooth_scroll: yes
---

#### Jasmin Gill Jg65472


```{r setup, include=FALSE}
library(knitr)
hook_output = knit_hooks$get('output')
knit_hooks$set(output = function(x, options) {
  # this hook is used only when the linewidth option is not NULL
  if (!is.null(n <- options$linewidth)) {
    x = knitr:::split_lines(x)
    # any lines wider than n should be wrapped
    if (any(nchar(x) > n)) x = strwrap(x, width = n)
    x = paste(x, collapse = '\n')
  }
  hook_output(x, options)
})

knitr::opts_chunk$set(echo = TRUE, eval = TRUE,fig.align="center",warning=FALSE,message=FALSE,fig.width=8, fig.height=5, linewidth=60)
options(tibble.width = 100,width = 100)
library(tidyverse)
```

# Modeling

# 0
```{R}
library("boot")
data("melanoma")
melanoma<-subset(melanoma, select = -year)
#help(melanoma)
```
The dataset that I used was melanoma, this is data from Connecticut Tumor Registry. It presents age adjusted numbers of melanoma skin cancer incidences per 100,000 people in Connecitcut from 1936-1972. Some of the variables that it includes is age, year, status, ulcer, thickness, and sex. A variable that I took out was year just because I thought I already had a lot of variables.

# 1
```{R}
age<-melanoma$age
time<-melanoma$time
thickness<-melanoma$thickness
ulcer<-melanoma$ulcer
status<-melanoma$status
sex<-melanoma$sex
man1<-manova(cbind(age,thickness,ulcer,time)~status, data=melanoma)
summary(man1)
summary.aov(man1)
pairwise.t.test(age, status, p.adj = "none")
pairwise.t.test(time, status, p.adj = "none")
pairwise.t.test(thickness, status, p.adj = "none")
pairwise.t.test(ulcer, status, p.adj = "none")
0.05/4
```
A MANOVA test was performed to test if any of my numerical variables would show a mean different among levels on one of my categorical variables. The p values was 4.352e-07 which shows that there is a mean difference across levels of one of my categorical variables. So a ANOVA test was performed to find responses showing a mean difference across groups. Four post-hoc t tests were also performed to find which groups differ. All 4 tests differed by status. Since 4 hypothesis tests have been done, this requires an alteration in the 0.05 significance level. After adjusting the significance level, the new level is now 0.0125 and there is is still overall significance in all post-hoc tests. The assumptions have been met. 

# 2
```{R}
library(tidyverse)

obs_F<-8.8801

random<-replicate(5000,{  new<-melanoma%>%mutate(thickness=sample(thickness))  
SSW<- new%>%group_by(status)%>%summarize(SSW=sum((thickness-mean(thickness))^2))%>%summarize(sum(SSW))%>%pull 
SSB<- new%>%mutate(mean=mean(thickness))%>%group_by(status)%>%mutate(groupmean=mean(thickness))%>%    summarize(SSB=sum((mean-groupmean)^2))%>%summarize(sum(SSB))%>%pull  
(SSB/1)/(SSW/203) }) 

hist(random, prob=T); abline(v = obs_F, col="red",add=T)

mean(random>obs_F)
```
The randomization test that I chose to perform is a permutation test. A permutation test determines whether the observed difference between the sample mens is large enough. The null hypothesis is that the data drawn from is the same distribution as the data drawn. The alternative hypothesis is that the data drawn from is not the same distribution as the data drawn from. The histogram shifts more to the left side, favoring zero the most. the mean of mean(random>obs_F) gave a value of 0.0156.

# 3
```{R}
melanoma_fit<- lm(time~age*thickness, data = melanoma)
summary(melanoma_fit)

try<- lm(time~age, data=melanoma)



melanoma_fit%>%ggplot(aes(time, age*thickness))+geom_point()+geom_smooth(method = "lm", se = F)

summary(try)

library(lmtest)
coeftest(try, vcov=vcov(try))

melanoma_unfit<-lm(time~age+thickness, data = melanoma)
summary(melanoma_unfit)
```
The intercept has a big positive change in it's slope while holding all other variables constant. For age, the coefficients tell us that there is a negative change in the slope in the data while all other variables were held constant. The coefficient for the thickness shows that there is a big positive change in the slope while all other variables are held constant. For the age:thickness, there was a small negative change in the slope while all other variables were held constant. A graph was made using the ggplot() to graph the regression. The line in the graph shows a negative slope. There are way too many outliers, and it does not seem that the linearity, normaily, and homoskedasticity assumptions are met graphically. After doing the heteroskedasticity test, the p-value showed to be significant which let me reject the null hypothesis. The SE's decreased slightly from the SE's before. The model explains a proportion of 0.1277 of the variation in the outcome. It seems that SE's decreased a lot in the one without the interactions as compared to the one where to the one with the interactions. 

# 4
```{R}
set.seed(348) 
 
lm(time~age*thickness, data = melanoma)
summary(melanoma_fit)

resids<-melanoma_fit$residuals

fitted<-melanoma_fit$fitted.values

new_resids<-sample(resids,replace=TRUE)

melanoma$new_y<-fitted+new_resids 

fit9<-lm(new_y~time,data=melanoma)

resid_resamp<-replicate(5000,new_resids,melanoma$new_y) 

coef(fit9)

samp<-resid_resamp%>%as.data.frame%>%summarize_all(sd) 

sample(500)
```
The same regression model, the one with the interactions was ran. This time, I computed bootstrapped standard errors. The p value decreased more from before whereas the standard errors increased from the original SE and the robust SE.

# 5
```{R}
class_diag<-function(probs,truth){
 tab<-table(factor(probs>.5,levels=c("FALSE","TRUE")),truth)
 acc=sum(diag(tab))/sum(tab)
 sens=tab[2,2]/colSums(tab)[2]
 spec=tab[1,1]/colSums(tab)[1]
 ppv=tab[2,2]/rowSums(tab)[2]
 if(is.numeric(truth)==FALSE & is.logical(truth)==FALSE) truth<-as.numeric(truth)-1
 #CALCULATE EXACT AUC
 ord<-order(probs, decreasing=TRUE)
 probs <- probs[ord]; truth <- truth[ord]
 TPR=cumsum(truth)/max(1,sum(truth))
 FPR=cumsum(!truth)/max(1,sum(!truth))
 dup<-c(probs[-1]>=probs[-length(probs)], FALSE)
 TPR<-c(0,TPR[!dup],1); FPR<-c(0,FPR[!dup],1)
 n <- length(TPR)
 auc<- sum( ((TPR[-1]+TPR[-n])/2) * (FPR[-1]-FPR[-n]) )
 data.frame(acc,sens,spec,ppv,auc)
} 



fit1<-glm(ulcer~thickness+time, data= melanoma, family = binomial(link = "logit"))

summary(fit1)

coeftest(fit1)

prob<-predict(fit1,type="response")

y<-ifelse(melanoma$ulcer==1,1,0)

table(predict=as.numeric(prob>.5),truth=y)%>%addmargins

(100+53)/205 #accuracy
53/90 #Sens
100/115 #Spec
53/68 #PPV

stat<-class_diag(prob, ulcer)

odds<-function(p)p/(1-p) 
p<-seq(0,1,by=.1) 
cbind(p, odds=odds(p))%>%round(4)


ggplot()+stat_function(aes(p),fun=odds,geom="line")+ ylab("odds(p)")+xlab("ulcer")

ROC1<-data.frame(stat$sens,stat$spec,cutoff=seq(0,1,.01)) 

Sensitivity<-stat$sens
Specificity<-stat$spec

ROCplot<-ggplot(ROC1)+geom_path(aes(Sensitivity,Specificity),size=1.5)+geom_segment(aes(x=0,y=0,xend=1,yend=1),lty=2)+  scale_x_continuous(limits = c(0,1))

ROCplot

library(plotROC)

ROCplot<-ggplot(melanoma)+geom_roc(aes(d=y,m=prob), n.cuts=0) 

ROCplot

calc_auc(ROCplot)

set.seed(1234)

fraction<-0.5 
try3<-floor(fraction*nrow(melanoma)) 
iter<-500 
diags<-NULL
for(i in 1:iter){
 
 try_index<-sample(1:nrow(melanoma),size=try3)
 train<-melanoma[try_index,]
 test<-melanoma[-try_index,]
 truth<-test$y

 probs<-predict(fit1,newdata = test,type="response")
 
  diags1<-rbind(diags,class_diag(probs,test$new_y))
}

apply(diags1,2,mean)
```
For the intercept, there was a slight negative change in its slope while holding all other variables constant. For the coefficient was a slight positive change in the slope for thickness while holding all other variables constant. For time coefficient, there was a slight negative change in the slope while holding other variables constant. The accuracy for the model is 0.7463415, the sensitivity is 0.5888889, the specificity is 0.8695652, and the PPV is 0.7794118. ggplot was used to plot the density of log-odds by my binary outcome variable. A ROC plot was also generated that somewhat represents a log graph. The auc calculated was 0.8171014 using a calc_auc. This AUC is close to 1 so it shows that it should have good measure of seperability. A 10-fold CV was performed along with a report of the average accuracy, sensitivity, and recall.

# 6
```{R eval=F}
library(glmnet)

x1 = model.matrix(fit1, melanoma)[, -1] 
y2 <- as.matrix(melanoma$sex) 
 
cv <- cv.glmnet(x1, y2, family = "binomial") 
cv

lasso <- glmnet(x1, y2, family = "binomial", lambda = cv$lambda.1se)
coef(lasso)

fraction<-0.5 
try5<-floor(fraction*nrow(melanoma)) 
iter<-500 
diags<-NULL
for(i in 1:iter){
 
 try_index<-sample(1:nrow(melanoma),size=try5)
 train<-melanoma[try_index,]
 test<-melanoma[-try_index,]
 truth<-test$y
 
 fit9 <- glm(sex ~thickness+time+ulcer+status+ age ,data = melanoma,family = "binomial")
 
 fit9

 probs<-predict(fit9,newdata = test,type="response")
elp
 
  diags4<-rbind(diags,class_diag(probs,test$new_y))
}

apply(diags4,2,mean)
```
The variable that I chose to predict is the sex of the patients. A LASSO regression was ran while inputting all the other variables as predictors. The variables retained were the thickness, time, ulcer, and status. The response is binary and it seems that the accuracy of the logistic regression in part 5 and the accuracy in this question are very similar to one another. 

